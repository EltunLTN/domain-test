"""
Turbo.az Web Scraper
Bu script turbo.az saytÄ±ndan avtomobil mÉ™lumatlarÄ±nÄ± scrape edir vÉ™ CSV faylÄ±na yazÄ±r.
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from datetime import datetime
import random

class TurboAzScraper:
    def __init__(self):
        self.base_url = "https://turbo.az/autos"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'az-AZ,az;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }
        self.cars_data = []

    def clean_price(self, price_text):
        """QiymÉ™ti tÉ™mizlÉ™yir vÉ™ rÉ™qÉ™mÉ™ Ã§evirir"""
        if not price_text:
            return None
        # "12 500 AZN" -> 12500
        cleaned = re.sub(r'[^\d]', '', price_text)
        return int(cleaned) if cleaned else None

    def clean_number(self, text):
        """RÉ™qÉ™mlÉ™ri tÉ™mizlÉ™yir"""
        if not text:
            return None
        cleaned = re.sub(r'[^\d.]', '', text)
        return float(cleaned) if cleaned else None

    def scrape_page(self, page_num):
        """Bir sÉ™hifÉ™ni scrape edir"""
        print(f"Scraping sÉ™hifÉ™ {page_num}...")
        
        url = f"{self.base_url}?page={page_num}"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Turbo.az-da maÅŸÄ±n kartlarÄ±nÄ± tap (bu selectorlar turbo.az strukturuna gÃ¶rÉ™ dÉ™yiÅŸÉ™ bilÉ™r)
            car_listings = soup.find_all('div', class_='products-i')
            
            if not car_listings:
                print("MaÅŸÄ±n elanlarÄ± tapÄ±lmadÄ±. HTML strukturu dÉ™yiÅŸmiÅŸ ola bilÉ™r.")
                return False
            
            for listing in car_listings:
                car_data = self.extract_car_data(listing)
                if car_data:
                    self.cars_data.append(car_data)
            
            print(f"SÉ™hifÉ™ {page_num}: {len(car_listings)} elan scrape edildi")
            return True
            
        except requests.exceptions.RequestException as e:
            print(f"SÉ™hifÉ™ {page_num} scrape xÉ™tasÄ±: {e}")
            return False

    def extract_car_data(self, listing):
        """Bir elan mÉ™lumatlarÄ±nÄ± Ã§Ä±xarÄ±r"""
        try:
            car = {}
            
            # BaÅŸlÄ±q (Marka Model)
            title_elem = listing.find('div', class_='products-i__name')
            if title_elem:
                title = title_elem.text.strip()
                # "Mercedes-Benz E 200" -> brand: Mercedes-Benz, model: E 200
                parts = title.split(' ', 1)
                car['brand'] = parts[0] if len(parts) > 0 else None
                car['model'] = parts[1] if len(parts) > 1 else None
            else:
                return None
            
            # QiymÉ™t
            price_elem = listing.find('div', class_='product-price')
            if price_elem:
                car['price'] = self.clean_price(price_elem.text)
            else:
                return None  # QiymÉ™tsiz elanlarÄ± buraxÄ±rÄ±q
            
            # ParametrlÉ™r (Ä°l, YÃ¼rÃ¼ÅŸ, MÃ¼hÉ™rrik vÉ™ s.)
            params = listing.find_all('div', class_='products-i__attributes')
            if params:
                param_text = params[0].text if len(params) > 0 else ""
                
                # Ä°l
                year_match = re.search(r'(\d{4})', param_text)
                car['year'] = int(year_match.group(1)) if year_match else None
                
                # YÃ¼rÃ¼ÅŸ
                mileage_match = re.search(r'(\d+[\s\d]*)\s*km', param_text, re.IGNORECASE)
                car['mileage'] = self.clean_number(mileage_match.group(1)) if mileage_match else None
                
                # MÃ¼hÉ™rrik hÉ™cmi
                engine_match = re.search(r'(\d+\.?\d*)\s*L', param_text, re.IGNORECASE)
                car['engine_size'] = self.clean_number(engine_match.group(1)) if engine_match else None
            
            # ÅžÉ™hÉ™r
            city_elem = listing.find('div', class_='products-i__bottom-text')
            if city_elem:
                car['city'] = city_elem.text.strip()
            
            # Yanacaq nÃ¶vÃ¼, SÃ¼rÉ™tlÉ™r qutusu vÉ™ digÉ™r parametrlÉ™r
            # Bu mÉ™lumatlar É™traflÄ± sÉ™hifÉ™dÉ™ ola bilÉ™r, lakin sadÉ™lÉ™ÅŸdirmÉ™ Ã¼Ã§Ã¼n Ã¼mumi dÉ™yÉ™rlÉ™r veririk
            car['fuel_type'] = self.guess_fuel_type(listing.text)
            car['transmission'] = self.guess_transmission(listing.text)
            car['condition'] = 'yaxsi'  # Default
            car['owners'] = 1  # Default
            
            # YaradÄ±lma tarixi
            car['scraped_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            return car
            
        except Exception as e:
            print(f"MÉ™lumat Ã§Ä±xarma xÉ™tasÄ±: {e}")
            return None

    def guess_fuel_type(self, text):
        """MÉ™tndÉ™n yanacaq nÃ¶vÃ¼nÃ¼ tÉ™xmin edir"""
        text_lower = text.lower()
        if 'dizel' in text_lower or 'diesel' in text_lower:
            return 'dizel'
        elif 'hibrid' in text_lower or 'hybrid' in text_lower:
            return 'hibrid'
        elif 'elektrik' in text_lower or 'electric' in text_lower:
            return 'elektrik'
        elif 'qaz' in text_lower or 'gas' in text_lower:
            return 'qaz'
        else:
            return 'benzin'

    def guess_transmission(self, text):
        """MÉ™tndÉ™n sÃ¼rÉ™tlÉ™r qutusunu tÉ™xmin edir"""
        text_lower = text.lower()
        if 'mexaniki' in text_lower or 'manual' in text_lower:
            return 'mexaniki'
        elif 'robot' in text_lower:
            return 'robot'
        elif 'variator' in text_lower:
            return 'variator'
        else:
            return 'avtomat'

    def scrape_all(self, max_pages=100):
        """BÃ¼tÃ¼n sÉ™hifÉ™lÉ™ri scrape edir"""
        print(f"Turbo.az scraping baÅŸladÄ±...")
        print(f"Maksimum {max_pages} sÉ™hifÉ™ scrape edilÉ™cÉ™k")
        
        for page in range(1, max_pages + 1):
            success = self.scrape_page(page)
            
            if not success:
                print(f"SÉ™hifÉ™ {page}-dÉ™ problem. DayandÄ±rÄ±lÄ±r.")
                break
            
            # Rate limiting - saytÄ± yÃ¼klÉ™mÉ™mÉ™k Ã¼Ã§Ã¼n
            time.sleep(random.uniform(2, 4))
            
            # HÉ™r 10 sÉ™hifÉ™dÉ™ bir mÉ™lumat saxla
            if page % 10 == 0:
                self.save_data()
                print(f"âœ“ {len(self.cars_data)} mÉ™lumat indi saxlanÄ±ldÄ±")
        
        print(f"\nâœ“ Scraping tamamlandÄ±! CÉ™mi {len(self.cars_data)} avtomobil mÉ™lumatÄ± toplandÄ±")

    def save_data(self, filename='car_data.csv'):
        """MÉ™lumatlarÄ± CSV faylÄ±na yazÄ±r"""
        if not self.cars_data:
            print("SaxlanÄ±lacaq mÉ™lumat yoxdur")
            return
        
        df = pd.DataFrame(self.cars_data)
        
        # DublikatlarÄ± sil
        df = df.drop_duplicates(subset=['brand', 'model', 'year', 'price', 'mileage'])
        
        # CSV-yÉ™ yaz
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ“ MÉ™lumatlar '{filename}' faylÄ±na yazÄ±ldÄ± ({len(df)} sÉ™tir)")

    def clean_and_prepare_data(self, input_file='car_data.csv', output_file='car_data_cleaned.csv'):
        """MÉ™lumatlarÄ± tÉ™mizlÉ™yir vÉ™ ML Ã¼Ã§Ã¼n hazÄ±rlayÄ±r"""
        print("MÉ™lumatlar tÉ™mizlÉ™nir...")
        
        df = pd.read_csv(input_file)
        
        # Null dÉ™yÉ™rlÉ™ri sil
        df = df.dropna(subset=['price', 'year', 'mileage', 'brand', 'model'])
        
        # QiymÉ™t > 0
        df = df[df['price'] > 0]
        
        # Ä°l aralÄ±ÄŸÄ± (1990-2026)
        df = df[(df['year'] >= 1990) & (df['year'] <= 2026)]
        
        # YÃ¼rÃ¼ÅŸ > 0
        df = df[df['mileage'] >= 0]
        
        # Outlier-lÉ™ri sil (qiymÉ™t Ã§ox yÃ¼ksÉ™k/aÅŸaÄŸÄ±)
        price_q1 = df['price'].quantile(0.01)
        price_q99 = df['price'].quantile(0.99)
        df = df[(df['price'] >= price_q1) & (df['price'] <= price_q99)]
        
        # TÉ™mizlÉ™nmiÅŸ datanÄ± saxla
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ“ TÉ™mizlÉ™nmiÅŸ mÉ™lumatlar '{output_file}' faylÄ±na yazÄ±ldÄ± ({len(df)} sÉ™tir)")
        
        return df


def main():
    """Ana funksiya"""
    scraper = TurboAzScraper()
    
    # 1. Scraping et (100 sÉ™hifÉ™ = tÉ™xminÉ™n 2000-3000 maÅŸÄ±n)
    scraper.scrape_all(max_pages=100)
    
    # 2. Ä°lkin mÉ™lumatlarÄ± saxla
    scraper.save_data('car_data_raw.csv')
    
    # 3. TÉ™mizlÉ™ vÉ™ hazÄ±rla
    scraper.clean_and_prepare_data('car_data_raw.csv', 'car_data_cleaned.csv')
    
    print("\nðŸŽ‰ BÃ¼tÃ¼n É™mÉ™liyyatlar tamamlandÄ±!")
    print("car_data_cleaned.csv faylÄ± ML model Ã¼Ã§Ã¼n hazÄ±rdÄ±r")


if __name__ == "__main__":
    main()
