"""
Turbo.az Web Scraper - YENIL∆èNMI≈û VERSƒ∞YA
Bu script turbo.az saytƒ±ndan avtomobil m…ôlumatlarƒ±nƒ± scrape edir.
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from datetime import datetime
import random

class TurboAzScraper:
    def __init__(self):
        self.base_url = "https://turbo.az/autos"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'az-AZ,az;q=0.9',
        }
        self.cars_data = []

    def extract_car_data(self, listing):
        """HTML listing-d…ôn m…ôlumatlarƒ± √ßƒ±xarƒ±r"""
        try:
            car = {}
            
            # Link-d…ôn m…ôlumat al
            link = listing.find('a', class_='products-i__link')
            if not link:
                return None
            
            # Qiym…ôt - products-i__price
            price_elem = listing.find('div', class_='product-price')
            if not price_elem:
                price_elem = listing.find('span', class_='price')
            
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                # "12,500 ‚Çº" -> 12500
                price_clean = re.sub(r'[^\d]', '', price_text)
                car['price'] = int(price_clean) if price_clean else None
            else:
                return None
            
            # Ba≈ülƒ±q v…ô parametrl…ôr - products-i__name
            name_elem = listing.find('div', class_='products-i__name')
            if name_elem:
                title_text = name_elem.get_text(strip=True)
                # "Mercedes-Benz E 200" kimi
                parts = title_text.split(',')[0].strip().split(' ', 1)
                car['brand'] = parts[0] if len(parts) > 0 else 'Unknown'
                car['model'] = parts[1] if len(parts) > 1 else 'Unknown'
            else:
                return None
            
            # Parametrl…ôr - products-i__attributes (il, y√ºr√º≈ü, m√ºh…ôrrik)
            attrs = listing.find_all('div', class_='products-i__attributes')
            if attrs:
                attr_text = ' '.join([a.get_text() for a in attrs])
                
                # ƒ∞l
                year_match = re.search(r'(\d{4})\s*il', attr_text)
                if not year_match:
                    year_match = re.search(r'(\d{4})', attr_text)
                car['year'] = int(year_match.group(1)) if year_match else 2020
                
                # Y√ºr√º≈ü (km)
                mileage_match = re.search(r'(\d[\d\s]*)\s*km', attr_text, re.IGNORECASE)
                if mileage_match:
                    mileage_str = re.sub(r'\s', '', mileage_match.group(1))
                    car['mileage'] = int(mileage_str)
                else:
                    car['mileage'] = 50000  # Default
                
                # M√ºh…ôrrik h…ôcmi
                engine_match = re.search(r'(\d+\.?\d*)\s*L', attr_text, re.IGNORECASE)
                car['engine_size'] = float(engine_match.group(1)) if engine_match else 2.0
            else:
                car['year'] = 2020
                car['mileage'] = 50000
                car['engine_size'] = 2.0
            
            # ≈û…ôh…ôr - products-i__bottom
            city_elem = listing.find('div', class_='products-i__bottom')
            if city_elem:
                city_text = city_elem.get_text(strip=True)
                car['city'] = city_text.split(',')[0] if ',' in city_text else 'Bakƒ±'
            else:
                car['city'] = 'Bakƒ±'
            
            # Yanacaq v…ô transmissiya - t…ôxmin
            full_text = listing.get_text().lower()
            car['fuel_type'] = self.guess_fuel_type(full_text)
            car['transmission'] = self.guess_transmission(full_text)
            car['condition'] = 'yaxsi'
            car['owners'] = 1
            car['scraped_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            return car
            
        except Exception as e:
            print(f"‚ö†Ô∏è M…ôlumat √ßƒ±xarma x…ôtasƒ±: {e}")
            return None

    def guess_fuel_type(self, text):
        """Yanacaq n√∂v√ºn√º t…ôxmin edir"""
        if 'dizel' in text or 'diesel' in text:
            return 'dizel'
        elif 'hibrid' in text or 'hybrid' in text:
            return 'hibrid'
        elif 'elektrik' in text or 'electric' in text:
            return 'elektrik'
        elif 'qaz' in text:
            return 'qaz'
        return 'benzin'

    def guess_transmission(self, text):
        """Transmissiya n√∂v√ºn√º t…ôxmin edir"""
        if 'mexaniki' in text or 'manual' in text:
            return 'mexaniki'
        elif 'robot' in text:
            return 'robot'
        elif 'variator' in text:
            return 'variator'
        return 'avtomat'

    def scrape_page(self, page_num):
        """Bir s…ôhif…ôni scrape edir"""
        print(f"üìÑ Scraping s…ôhif…ô {page_num}...")
        
        url = f"{self.base_url}?page={page_num}"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Yeni struktur: <div class="products-i vipped featured">
            car_listings = soup.find_all('div', class_='products-i')
            
            if not car_listings:
                # Debug √º√ß√ºn HTML saxla
                with open('turbo_debug.html', 'w', encoding='utf-8') as f:
                    f.write(soup.prettify())
                print("‚ö†Ô∏è Elan tapƒ±lmadƒ±. HTML: turbo_debug.html")
                return False
            
            count = 0
            for listing in car_listings:
                car_data = self.extract_car_data(listing)
                if car_data:
                    self.cars_data.append(car_data)
                    count += 1
            
            print(f"‚úÖ S…ôhif…ô {page_num}: {count}/{len(car_listings)} elan scrape edildi")
            return count > 0
            
        except Exception as e:
            print(f"‚ùå S…ôhif…ô {page_num} x…ôtasƒ±: {e}")
            return False

    def scrape_all(self, max_pages=50):
        """B√ºt√ºn s…ôhif…ôl…ôri scrape edir"""
        print(f"\nüöó Turbo.az Scraping Ba≈üladƒ±")
        print(f"üìä Maksimum {max_pages} s…ôhif…ô\n")
        
        for page in range(1, max_pages + 1):
            success = self.scrape_page(page)
            
            if not success and page == 1:
                print("‚ùå ƒ∞lk s…ôhif…ô scrape edilm…ôdi. Dayandƒ±rƒ±lƒ±r.")
                break
            elif not success:
                print(f"‚ö†Ô∏è S…ôhif…ô {page} bo≈üdur. Scraping tamamlandƒ±.")
                break
            
            # Rate limiting
            time.sleep(random.uniform(2, 4))
            
            # H…ôr 10 s…ôhif…ôd…ô saxla
            if page % 10 == 0:
                self.save_data('car_data_temp.csv')
                print(f"üíæ Progress saxlanƒ±ldƒ±: {len(self.cars_data)} elan\n")
        
        print(f"\n‚úÖ Scraping tamamlandƒ±!")
        print(f"üìä Toplam: {len(self.cars_data)} avtomobil m…ôlumatƒ±")

    def save_data(self, filename='car_data.csv'):
        """CSV faylƒ±na yaz"""
        if not self.cars_data:
            print("‚ö†Ô∏è Saxlanƒ±lacaq m…ôlumat yoxdur")
            return
        
        df = pd.DataFrame(self.cars_data)
        df = df.drop_duplicates(subset=['brand', 'model', 'year', 'price'])
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"‚úÖ {len(df)} elan '{filename}' faylƒ±na yazƒ±ldƒ±")

    def clean_and_prepare_data(self, input_file, output_file):
        """M…ôlumatlarƒ± t…ômizl…ô v…ô ML √º√ß√ºn hazƒ±rla"""
        print("\nüßπ M…ôlumatlar t…ômizl…ônir...")
        
        try:
            df = pd.read_csv(input_file)
        except FileNotFoundError:
            print(f"‚ùå {input_file} tapƒ±lmadƒ±. Scraping edilmi≈ü m…ôlumat yoxdur.")
            return
        
        # Null d…ôy…ôrl…ôri sil
        df = df.dropna(subset=['price', 'year', 'brand', 'model'])
        
        # Qiym…ôt v…ô il filtrl…ôri
        df = df[df['price'] > 1000]
        df = df[(df['year'] >= 1990) & (df['year'] <= 2026)]
        df = df[df['mileage'] >= 0]
        
        # Outlier-l…ôri sil
        price_q1 = df['price'].quantile(0.01)
        price_q99 = df['price'].quantile(0.99)
        df = df[(df['price'] >= price_q1) & (df['price'] <= price_q99)]
        
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"‚úÖ {len(df)} t…ômiz m…ôlumat '{output_file}' faylƒ±na yazƒ±ldƒ±")


def main():
    """Ana funksiya"""
    scraper = TurboAzScraper()
    
    # 1. Scraping (50 s…ôhif…ô ~ 1000 elan)
    scraper.scrape_all(max_pages=50)
    
    # 2. ƒ∞lkin saxla
    if scraper.cars_data:
        scraper.save_data('car_data_raw.csv')
        
        # 3. T…ômizl…ô
        scraper.clean_and_prepare_data('car_data_raw.csv', 'car_data_cleaned.csv')
    else:
        print("\n‚ö†Ô∏è Scraping uƒüursuz oldu. Sample dataset istifad…ô edin.")
        print("car_data_sample.csv faylƒ±nƒ± car_data_cleaned.csv olaraq kopyalayƒ±n:")
        print("copy car_data_sample.csv car_data_cleaned.csv")


if __name__ == "__main__":
    main()
